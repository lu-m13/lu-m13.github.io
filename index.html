<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lu Ming</title>
  
  <meta name="author" content="Lu Ming">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lu Ming</name>
              </p>
              <p>I am a research scientist at Vision and AI Lab (VAIL), <a href="https://www.intel.com">Intel Labs China</a>, where I work on computer graphics and 3D vision. I did my PhD at <a href="https://www.ee.tsinghua.edu.cn/">Tsinghua University</a>, where I was advised by <a href="http://web.ee.tsinghua.edu.cn/zhangli/zh_CN/index.htm">Prof. Zhang Li</a>. 
              </p>
              <p>I've collaborated closely with <a href="http://xufeng.site/">Prof. Xu Feng</a>, <a href="https://www.shanghangzhang.com/">Prof. Zhang Shanghang</a>, <a href="https://www.fst.um.edu.mo/personal/ehwu/">Prof. Wu Enhua</a>, <a href="https://faculty.bjtu.edu.cn/rjxy/8947.html">Prof. Zhang Shunli</a> and <a href="https://yaoanbang.github.io/">Dr. Yao Anbang</a>.
              </p>
              <p>
              <span class="highlight">For Computer Graphics (2013-now),</span> I've worked on <span class="highlight">developing</span> high-quality, efficient, scalable, intelligent visual synthesis systems. I'm especially interested in visual content capture (3D face/body/gaze/object/scene/etc.) and enhancement (super-resolution/denoising/interpolation/style transfer/relighting/etc.). 
              </p>
              <p>
                <span class="highlight">For 3D Vision (2022-now),</span> I've worked on <span class="highlight">improving</span> the quality, efficiency, scalability and intelligence of indoor and outdoor applications such as visual navigation and autonomous driving.
              </p>
              <p>
                <span class="highlight">Only my favourite papers are listed. If you are interested in my research, do not hesitate to contact me for potential collaborations.</span>
              </p>
              <p style="text-align:center">
                <a href="mailto:lu199192@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/luming_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="data/luming_bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=3vArSU0AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lu-m13/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/luming2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/luming2_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Thanks Note</heading>
            <p>At the age of fifteen (2006), I had an accident, which yields TMJ Disorders. Over the past 16 years, I was tortured by severe headache and insomnia, which even changed my personality. I took lots of physical examinations like brain tumor, ankylosing spondylitis, etc. However, I never knew the cause is TMJ Disorders until 2022/10/1. I would like to thank all the doctors, colleagues, friends, classmates and my family for their kindness during the tough 16 years. I especially thank my parents, who unconditionally believe and encourage me. Here, I would like to thank you all.
            </p>
          </td>
          </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Computer Graphics Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bmvc21_sampling.png" alt="blind-date" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2111.15185.pdf">
                <papertitle>SamplingAug: On the Importance of Patch Sampling Augmentation for Single Image Super-Resolution</papertitle>
              </a>
              <br>
              Shizun Wang*, <strong>Ming Lu*</strong>, Kaixin Chen, <a href="https://liujiaming1996.github.io/">Jiaming Liu</a>, Xiaoqi Li, Ming Wu
              <br>
              <em>British Machine Vision Conference</em>, 2021
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv21_cafm.png" alt="blind-date" width="160" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Overfitting_the_Data_Compact_Neural_Video_Delivery_via_Content-Aware_Feature_ICCV_2021_paper.pdf">
                <papertitle>Overfitting the Data: Compact Neural Video Delivery via Content-aware Feature Modulation</papertitle>
              </a>
              <br>
              <a href="https://liujiaming1996.github.io/">Jiaming Liu*</a>, <strong>Ming Lu*</strong>, Kaixin Chen, Xiaoqi Li, Shizun Wang, Zhaoqing Wang, Enhua Wu, Yurong Chen, Chuang Zhang, Ming Wu
              <br>
              <em>International Conference on Computer Vision</em>, 2021
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tvcg20_detail.jpg" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9239985">
                <papertitle>Emotion-preserving Blendshape Update with Real-time Face Tracking</papertitle>
              </a>
              <br>
              <a href="https://sireer.github.io/">Zhibo Wang</a>, Jingwang Ling, Chengzeng Feng, <strong>Ming Lu</strong>, <a href="http://xufeng.site/">Feng Xu</a>
              <br>
              <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2020
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv19_ost.jpg" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Lu_A_Closed-Form_Solution_to_Universal_Style_Transfer_ICCV_2019_paper.pdf">
                <papertitle>A Closed-Form Solution to Universal Style Transfer</papertitle>
              </a>
              <br>
              <strong>Ming Lu</strong>, <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>, <a href="https://yaoanbang.github.io/">Anbang Yao</a>, <a href="https://scholar.google.com/citations?user=MKRyHXsAAAAJ&hl=en">Yurong Chen</a>, <a href="http://xufeng.site/">Feng Xu</a>, <a href="http://web.ee.tsinghua.edu.cn/zhangli/zh_CN/index.htm">Zhang Li</a>
              <br>
              <em>International Conference on Computer Vision</em>, 2019
              <p></p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>3D Vision Research</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/arxiv2022_uncertainty.png" alt="blind-date" width="160" height="80">
          </td>
          <td width="75%" valign="middle">
            <a href="https://arxiv.org/pdf/2208.12653.pdf">
              <papertitle>UNCERTAINTY-GUIDED DEPTH FUSION FOR SPIKE CAMERA</papertitle>
            </a>
            <br>
            Jianing Li*, Jiaming Liu, Xiaobao Wei, Jiyuan Zhang, Ming Lu, Lei Ma, Li Du, Tiejun Huang, Shanghang Zhang
            <br>
            <em>arxiv</em>, 2022
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/arxiv2022_bicross.png" alt="blind-date" width="160" height="80">
          </td>
          <td width="75%" valign="middle">
            <a href="https://arxiv.org/pdf/2208.12527.pdf">
              <papertitle>Unsupervised Spike Depth Estimation via Cross-modality Cross-domain Knowledge Transfer</papertitle>
            </a>
            <br>
            Jiaming Liu*, Qizhe Zhang, Jianing Li, Ming Lu, Tiejun Huang, Shanghang Zhang
            <br>
            <em>arxiv</em>, 2022
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/cvpr17_room.png" alt="blind-date" width="160" height="80">
          </td>
          <td width="75%" valign="middle">
            <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhao_Physics_Inspired_Optimization_CVPR_2017_paper.pdf">
              <papertitle>Physics Inspired Optimization on Semantic Transfer Features: An Alternative Method for Room Layout Estimation</papertitle>
            </a>
            <br>
            Hao Zhao*, <strong>Ming Lu*</strong>, Anbang Yao, Yiwen Guo, Yurong Chen, Li Zhang
            <br>
            <em>Computer Vision and Pattern Recognition</em>, 2017
            <p></p>
          </td>
        </tr>
      </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/proj17_chris.jpg" alt="blind-date" width="160" height="100"></td>
          <td width="75%" valign="center">
            <a href="https://www.youtube.com/watch?v=c5-iIheUlyI">Our 3D face technique has been applied to Chris Lee's MV</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/proj22_olympic.jpg" alt="blind-date" width="160" height="120"></td>
          <td width="75%" valign="center">
            <a href="https://www.intel.com/content/www/us/en/sports/olympic-games/overview.html">Our 3D body technique has been applied to the opening ceremony of Winter Olympic Games 2022</a>
          </td>
        </tr>
				
      </td>
    </tr>
  </table>
</body>

</html>
