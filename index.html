<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lu Ming</title>
  
  <meta name="author" content="Lu Ming">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lu Ming</name>
              </p>
              <p>I am a research scientist at AI Research Lab (AIRL), <a href="https://www.intel.com/content/www/us/en/research/overview.html">Intel Labs</a>, where I work on <span class="highlight">Enhanced Visual AI (EVAI)</span>. I did my Ph.D focused on computer graphics and 3D vision at <a href="https://www.ee.tsinghua.edu.cn/">Tsinghua University</a>, where I was advised by <a href="http://web.ee.tsinghua.edu.cn/zhangli/zh_CN/index.htm">Prof. Zhang Li</a>. 
              <p>
                I'm especially interested in AI + Chips (ISP/Codec/GPU/etc.), Neural Field (NeRF/3DGS/3D Occupancy/etc.), and training-free/training-efficient enhancement for Large AI Models (SAM/Diffusion Model/LLaVA/etc.).
              </p>
	      <p>
        	I'm also interested in applying EVAI techniques to digital human, autonomous driving, embodied AI, and AI4Science. 
              </p>
	      <p>
        	<span class="highlight">Enhancing visual AI by enhancing visual data/model/compute.</span>
              </p>    
              <p style="text-align:center">
                <a href="data/research_intro2.pdf">Research Intro</a> &nbsp/&nbsp
                <a href="mailto:lu199192@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/luming_cv20221105.pdf">CV</a> &nbsp/&nbsp
                <a href="data/luming_bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=3vArSU0AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lu-m13/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/luming4.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/luming4.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Visual Synthesis Research, Partly</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mm2024_ses.png" alt="blind-date" width="160" height="70">
            </td>
            <td width="75%" valign="middle">
              <a href="data/mm2024_ses_paper.pdf">
                <papertitle>Superpixel-based Efficient Sampling for Learning Neural Fields from Large Input</papertitle>
              </a>
              <br>
              Zhongwei Xuan, Zunjie Zhu, Shuai Wang, Haibing Yin, Hongkui Wang, <strong>Ming Lu</strong>
              <br>
              <em>ACM Multimedia (MM)</em>, 2024
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvpr2024_nto3d.png" alt="blind-date" width="160" height="70">
            </td>
            <td width="75%" valign="middle">
              <a href="data/cvpr2024_nto3d_paper.pdf">
                <papertitle>NTO3D: Neural Target Object 3D Reconstruction with Segment Anything</papertitle>
              </a>
              <br>
              Xiaobao Wei, Renrui Zhang, Jiarui Wu, Jiaming Liu, <strong>Ming Lu</strong>, Yandong Guo, Shanghang Zhang
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2024
              <p></p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvpr2023_cabm.png" alt="blind-date" width="160" height="70">
            </td>
            <td width="75%" valign="middle">
              <a href="data/cvpr2023_cabm_paper.pdf">
                <papertitle>CABM: Content-Aware Bit Mapping for Single Image Super-Resolution Network with Large Input</papertitle>
              </a>
              <br>
              Senmao Tian, <strong>Ming Lu</strong>, Jiaming Liu, Yandong Guo, Yurong Chen, Shunli Zhang
              <br>
              <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023
              <p></p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eccv2022_semm.png" alt="blind-date" width="160" height="70">
            </td>
            <td width="75%" valign="middle">
              <a href="data/eccv2022_semm_paper.pdf">
                <papertitle>Structure-aware Editable Morphable Model for 3D Facial Detail Animation and Manipulation</papertitle>
              </a>
              <br>
              Jingwang Ling, Zhibo Wang, <strong>Ming Lu</strong>, Quan Wang, Chen Qian, Feng Xu
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tvcg2022_detail.png" alt="blind-date" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              <a href="data/tvcg2022_detail_paper.pdf">
                <papertitle>Semantically Disentangled Variational Autoencoder for Modeling 3D Facial Details</papertitle>
              </a>
              <br>
              Jingwang Ling, Zhibo Wang, <strong>Ming Lu</strong>, Quan Wang, Chen Qian, Feng Xu
              <br>
              <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2022
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eccv2022_emt.png" alt="blind-date" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              <a href="data/eccv2022_emt_paper.pdf">
                <papertitle>Efficient Meta-Tuning for Content-aware Neural Video Delivery</papertitle>
              </a>
              <br>
              Xiaoqi Li, Jiaming Liu, Shizun Wang, Cheng Lyu, <strong>Ming Lu</strong>, Yurong Chen, Anbang Yao, Yandong Guo, Shanghang Zhang
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022
              <p></p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eccv2022_ape.png" alt="blind-date" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              <a href="data/eccv2022_ape_paper.pdf">
                <papertitle>Adaptive Patch Exiting for Scalable Single Image Super-Resolution</papertitle>
              </a>
              <br>
              Shizun Wang, Jiaming Liu, Kaixin Chen, Xiaoqi Li, <strong>Ming Lu</strong>, Yandong Guo
              <br>
              <em>European Conference on Computer Vision (ECCV Oral)</em>, 2022
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bmvc2021_sampling.png" alt="blind-date" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              <a href="data/bmvc2021_sampling_paper.pdf">
                <papertitle>SamplingAug: On the Importance of Patch Sampling Augmentation for Single Image Super-Resolution</papertitle>
              </a>
              <br>
              Shizun Wang, <strong>Ming Lu</strong>, Kaixin Chen, Jiaming Liu, Xiaoqi Li, Ming Wu
              <br>
              <em>British Machine Vision Conference (BMVC)</em>, 2021
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv2021_cafm.png" alt="blind-date" width="160" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="data/iccv2021_cafm_paper.pdf">
                <papertitle>Overfitting the Data: Compact Neural Video Delivery via Content-aware Feature Modulation</papertitle>
              </a>
              <br>
              Jiaming Liu, <strong>Ming Lu</strong>, Kaixin Chen, Xiaoqi Li, Shizun Wang, Zhaoqing Wang, Enhua Wu, Yurong Chen, Chuang Zhang, Ming Wu
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2021
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tvcg2020_detail.png" alt="blind-date" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="data/tvcg2020_detail_paper.pdf">
                <papertitle>Emotion-preserving Blendshape Update with Real-time Face Tracking</papertitle>
              </a>
              <br>
              Zhibo Wang, Jingwang Ling, Chengzeng Feng, <strong>Ming Lu</strong>, Feng Xu
              <br>
              <em>IEEE Transactions on Visualization and Computer Graphics (TVCG)</em>, 2020
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv2019_ost.png" alt="blind-date" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href="data/iccv2019_ost_paper.pdf">
                <papertitle>A Closed-Form Solution to Universal Style Transfer</papertitle>
              </a>
              <br>
              <strong>Ming Lu</strong>, Hao Zhao, Anbang Yao, Yurong Chen, Feng Xu, Zhang Li
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2019
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/siga2017_eyelid.png" alt="blind-date" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href="data/siga2017_eyelid_paper.pdf">
                <papertitle>Real-time 3D Eyelids Tracking from Semantic Edges</papertitle>
              </a>
              <br>
              Quan Wen, Feng Xu, <strong>Ming Lu</strong>, Junhai Yong
              <br>
              <em>SIGGRAPH Asia 2017</em>, 2017
              <p></p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Visual Understanding Research, Partly</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/eccv2024_imedsam.png" alt="blind-date" width="160" height="80">
          </td>
          <td width="75%" valign="middle">
            <a href="data/eccv2024_imedsam_paper.pdf">
              <papertitle>I-MedSAM: Implicit Medical Image Segmentation with Segment Anything</papertitle>
            </a>
            <br>
            Xiaobao Wei, Jiajun Cao, Yizhu Jin, <strong>Ming Lu</strong>, Guangyu Wang, Shanghang Zhang
            <br>
            <em>European Conference on Computer Vision (ECCV)</em>, 2024
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/cvpr2023_sanet.png" alt="blind-date" width="160" height="80">
          </td>
          <td width="75%" valign="middle">
            <a href="data/cvpr2023_sanet_paper_v5.pdf">
              <papertitle>BEV-SAN: Accurate BEV 3D Object Detection via Slice Attention Networks</papertitle>
            </a>
            <br>
            Xiaowei Chi, Jiaming Liu, <strong>Ming Lu</strong>, Rongyu Zhang, Zhaoqing Wang, Yandong Guo, Shanghang Zhang
            <br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/arxiv2022_lidarkd.png" alt="blind-date" width="160" height="100">
          </td>
          <td width="75%" valign="middle">
            <a href="data/arxiv2022_lidarkd_paper_v4.pdf">
              <papertitle>BEV-LGKD: A Unified LiDAR-Guided Knowledge Distillation Framework for BEV 3D Object Detection</papertitle>
            </a>
            <br>
            Jianing Li, <strong>Ming Lu</strong>, Jiaming Liu, Yandong Guo, Li Du, Shanghang Zhang
            <br>
            <em>arxiv</em>, 2022
            <p></p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/cvpr2017_room.png" alt="blind-date" width="160" height="80">
          </td>
          <td width="75%" valign="middle">
            <a href="data/cvpr2017_layout_paper.pdf">
              <papertitle>Physics Inspired Optimization on Semantic Transfer Features: An Alternative Method for Room Layout Estimation</papertitle>
            </a>
            <br>
            Hao Zhao, <strong>Ming Lu</strong>, Anbang Yao, Yiwen Guo, Yurong Chen, Li Zhang
            <br>
            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2017
            <p></p>
          </td>
        </tr>
      </tbody></table>
				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/proj2017_chris.jpg" alt="blind-date" width="160" height="100"></td>
          <td width="75%" valign="center">
            <a href="https://www.youtube.com/watch?v=c5-iIheUlyI">Our 3D face technique has been applied to Chris Lee's MV</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/proj2022_olympic.jpg" alt="blind-date" width="160" height="120"></td>
          <td width="75%" valign="center">
            <a href="https://www.intel.com/content/www/us/en/sports/olympic-games/overview.html">Our 3D body technique has been applied to the opening ceremony of Winter Olympic Games 2022</a>
          </td>
        </tr>
				
      </td>
    </tr>
  </table>
</body>

</html>
