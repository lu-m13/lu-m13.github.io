<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lu Ming</title>
  
  <meta name="author" content="Lu Ming">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lu Ming</name>
              </p>
              <p>I am a research scientist at <a href="https://www.intel.com">Intel Labs China</a>, where I work on computer graphics and machine learning.
              </p>
              <p>
                At Intel I've worked on developing <span class="highlight">high-quality/efficient/scalable/intelligent visual synthesis systems</span>. I did my PhD at <a href="https://www.ee.tsinghua.edu.cn/">Tsinghua University</a>, where I was advised by <a href="http://web.ee.tsinghua.edu.cn/zhangli/zh_CN/index.htm">Prof. Zhang Li</a>. I've collaborated closely with <a href="http://xufeng.site/">Prof. Xu Feng</a> and <a href="https://yaoanbang.github.io/">Dr. Yao Anbang</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:lu199192@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/luming_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="data/luming_bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=3vArSU0AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lu-m13/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/luming2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/luming2_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm especially interested in visual content capture (3D face/body/gaze/etc.) and enhancement (super-resolution/denoising/interpolation/style transfer/etc.). <span class="highlight">Only my favourite papers are listed</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bmvc21_sampling.png" alt="blind-date" width="160" height="80">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2111.15185.pdf">
                <papertitle>SamplingAug: On the Importance of Patch Sampling Augmentation for Single Image Super-Resolution</papertitle>
              </a>
              <br>
              Shizun Wang*, <strong>Ming Lu*</strong>, Kaixin Chen, <a href="https://liujiaming1996.github.io/">Jiaming Liu</a>, Xiaoqi Li, Ming Wu
              <br>
              <em>British Machine Vision Conference</em>, 2021
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv21_cafm.png" alt="blind-date" width="160" height="120">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Overfitting_the_Data_Compact_Neural_Video_Delivery_via_Content-Aware_Feature_ICCV_2021_paper.pdf">
                <papertitle>Overfitting the Data: Compact Neural Video Delivery via Content-aware Feature Modulation</papertitle>
              </a>
              <br>
              <a href="https://liujiaming1996.github.io/">Jiaming Liu*</a>, <strong>Ming Lu*</strong>, Kaixin Chen, Xiaoqi Li, Shizun Wang, Zhaoqing Wang, Enhua Wu, Yurong Chen, Chuang Zhang, Ming Wu
              <br>
              <em>International Conference on Computer Vision</em>, 2021
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tvcg20_detail.jpg" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9239985">
                <papertitle>Emotion-preserving Blendshape Update with Real-time Face Tracking</papertitle>
              </a>
              <br>
              <a href="https://sireer.github.io/">Zhibo Wang</a>, Jingwang Ling, Chengzeng Feng, <strong>Ming Lu</strong>, <a href="http://xufeng.site/">Feng Xu</a>
              <br>
              <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2020
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccv19_ost.jpg" alt="blind-date" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Lu_A_Closed-Form_Solution_to_Universal_Style_Transfer_ICCV_2019_paper.pdf">
                <papertitle>A Closed-Form Solution to Universal Style Transfer</papertitle>
              </a>
              <br>
              <strong>Ming Lu</strong>, <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>, <a href="https://yaoanbang.github.io/">Anbang Yao</a>, <a href="https://scholar.google.com/citations?user=MKRyHXsAAAAJ&hl=en">Yurong Chen</a>, <a href="http://xufeng.site/">Feng Xu</a>, <a href="http://web.ee.tsinghua.edu.cn/zhangli/zh_CN/index.htm">Zhang Li</a>
              <br>
              <em>International Conference on Computer Vision</em>, 2019
              <p></p>
            </td>
          </tr>

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/proj17_chris.jpg" alt="blind-date" width="160" height="100"></td>
          <td width="75%" valign="center">
            <a href="https://www.youtube.com/watch?v=c5-iIheUlyI">Our 3D face technique has been applied to Chris Lee's MV</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/proj22_olympic.jpg" alt="blind-date" width="160" height="120"></td>
          <td width="75%" valign="center">
            <a href="https://www.intel.com/content/www/us/en/sports/olympic-games/overview.html">Our 3D body technique has been applied to the opening ceremony of Winter Olympic Games 2022</a>
          </td>
        </tr>
				
      </td>
    </tr>
  </table>
</body>

</html>
