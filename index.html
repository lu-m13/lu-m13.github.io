<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Lu Ming</title>
  
  <meta name="author" content="Lu Ming">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:0%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Lu Ming</name>
              </p>
			  <p>My research focuses on <span class="highlight">Model Optimization (ModelOpt)</span> for Computer Vision (CV) techniques. I obtained my Ph.D at <a href="https://www.ee.tsinghua.edu.cn/">Department of Electronic Engineering, Tsinghua University</a>, where I was advised by <a href="http://web.ee.tsinghua.edu.cn/zhangli/zh_CN/index.htm">Prof. Zhang Li</a>. 
              </p>
			  <p>
                I'm currently interested in <span class="highlight">1.</span> Large Vision-Language Models (post-training for VLM/VLA/VLN/Diffusion Model) and <span class="highlight">2.</span> Neural Fields (NeRF/3DGS/3DOcc). Previously, I worked on <span class="highlight">3.</span> Small Computer Vision Models (style transfer/super-resolution/object detection/etc) during my PhD and Post-Doc (2012-2022).
              </p>
	      <p>
        	I have published over 50 papers in top-tier journals and conference proceedings. I also have about 30 PCT/US/EP patents approved for filing. Some of my works have been featured in Intel's GPU/CPU, Chris Lee's MV, and the opening ceremony of the 2022 Winter Olympic Games.
              </p>    
              <p style="text-align:center">
                <a href="data/research_intro6.pdf">Research Intro</a> &nbsp/&nbsp
                <a href="mailto:lu199192@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/luming_cv20250724.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=3vArSU0AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lu-m13/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/luming2_circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/luming2_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading><u>Recent Papers</u></heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<p>[2025/11/09] Four papers accepted by AAAI 2026, 4 Large Vision-Language Models (FastDriveVLA, ManipDreamer3D, MMG-Vid, StreamKV)</p>
			
	<p>[2025/09/18] Two papers accepted by NeurIPS 2025, 2 Large Vision-Language Models (CDPruner, UniCTokens)</p>

			
	<p>[2025/07/07] Four papers accepted by ACM MM 2025, 3 Neural Fields (EmbodiedOcc++, MixedGaussianAvatar, VGNC), 1 Large Vision-Language Models (DepthDark)</p>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:0px;width:100%;vertical-align:middle">
            <heading><u>Large Vision-Language Models</u></heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>
          <td width="100%" valign="middle">
            <a href="https://arxiv.org/pdf/2501.01709">
              <papertitle>[1] MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders</papertitle>
            </a>
            <br>
            Jiajun Cao, Yuan Zhang, Tao Huang, <strong>Ming Lu</strong>, Qizhe Zhang, Ruichuan An, Ningning Ma, Shanghang Zhang
            <br>
            <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025
            <p></p>
          </td>
        </tr>

      	<tr>
        <td width="100%" valign="middle">
          <a href="https://arxiv.org/pdf/2412.01818">
            <papertitle>[2] Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs</papertitle>
          </a>
          <br>
	  Qizhe Zhang, Aosong Cheng, <strong>Ming Lu</strong>, Zhiyong Zhuo, Minqi Wang, Jiajun Cao, Shaobo Guo, Qi She, Shanghang Zhang
          <br>
          <em>International Conference on Computer Vision (ICCV)</em>, 2025
          <p></p>
        </td>
	</tr>

      	<tr>
        <td width="100%" valign="middle">
          <a href="https://arxiv.org/pdf/2506.10967">
            <papertitle>[3] Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs</papertitle>
          </a>
          <br>
	  Qizhe Zhang, Mengzhen Liu, Lichen Li, <strong>Ming Lu</strong>, Yuan Zhang, Junwen Pan, Qi She, Shanghang Zhang
          <br>
          <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2025
          <p></p>
        </td>
	</tr>

	<tr>
        <td width="100%" valign="middle">
          <a href="https://arxiv.org/pdf/2506.16119">
            <papertitle>[4] FastInit: Fast Noise Initialization for Temporally Consistent Video Generation</papertitle>
          </a>
          <br>
	  Chengyu Bai, Yuming Li, Zhongyu Zhao, Jintao Chen, Peidong Jia, Qi She, <strong>Ming Lu</strong>, Shanghang Zhang
          <br>
          <em>arXiv</em>, 2025
          <p></p>
        </td>
	</tr> 

	<tr>
        <td width="100%" valign="middle">
          <a href="https://www.arxiv.org/pdf/2506.16112">
            <papertitle>[5] AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models</papertitle>
          </a>
          <br>
	  Yuan Zhang, Chun-Kai Fan, Tao Huang, <strong>Ming Lu</strong>, Sicheng Yu, Junwen Pan, Kuan Cheng, Qi She, Shanghang Zhang
          <br>
          <em>arXiv</em>, 2025
          <p></p>
        </td>
	</tr> 

	<tr>
        <td width="100%" valign="middle">
          <a href="https://arxiv.org/pdf/2411.11706">
            <papertitle>[6] MC-LLaVA: Multi-Concept Personalized Vision-Language Model</papertitle>
          </a>
          <br>
	  Ruichuan An, Sihan Yang, <strong>Ming Lu</strong>, Renrui Zhang, Kai Zeng, Yulin Luo, Jiajun Cao, Hao Liang, Ying Chen, Qi She, Shanghang Zhang, Wentao Zhang
          <br>
          <em>arXiv</em>, 2025
          <p></p>
        </td>
	</tr> 

	<tr>
        <td width="100%" valign="middle">
          <a href="https://arxiv.org/pdf/2503.129996">
            <papertitle>[7] Concept-as-Tree: Synthetic Data is All You Need for VLM Personalization</papertitle>
          </a>
          <br>
	  Ruichuan An, Kai Zeng, <strong>Ming Lu</strong>, Sihan Yang, Renrui Zhang, Huitong Ji, Qizhe Zhang, Yulin Luo, Hao Liang, Wentao Zhang
          <br>
          <em>arXiv</em>, 2025
          <p></p>
        </td>
	</tr> 
	      
	<tr>
        <td width="100%" valign="middle">
          <a href="https://arxiv.org/pdf/2505.14671?">
            <papertitle>[8] UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens</papertitle>
          </a>
          <br>
	  Ruichuan An, Sihan Yang, Renrui Zhang, Zijun Shen, <strong>Ming Lu</strong>, Gaole Dai, Hao Liang, Ziyu Guo, Shilin Yan, Yulin Luo, Bocheng Zou, Chaoqun Yang, Wentao Zhang
          <br>
          <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2025
          <p></p>
        </td>
	</tr>

		  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading><u>Neural Fields</u></heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	
	<tr>
            <td width="100%" valign="middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3130800.3130837">
                <papertitle>[1] Real-time 3D Eyelids Tracking from Semantic Edges</papertitle>
              </a>
              <br>
              Quan Wen, Feng Xu, <strong>Ming Lu</strong>, Jun-Hai Yong
              <br>
              <em>ACM Transactions on Graphics (TOG)</em>, 2017
              <p></p>
            </td>
        </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9239985/">
                <papertitle>[2] Emotion-preserving Blendshape Update with Real-time Face Tracking</papertitle>
              </a>
              <br>
              Zhibo Wang, Jingwang Ling, Chengzeng Feng, <strong>Ming Lu</strong>, Feng Xu
              <br>
              <em>Transactions on Visualization and Computer Graphics (TVCG)</em>, 2020
              <p></p>
            </td>
        </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9756299/">
                <papertitle>[3] Semantically Disentangled Variational Autoencoder for Modeling 3D Facial Details</papertitle>
              </a>
              <br>
              Jingwang Ling, Zhibo Wang, <strong>Ming Lu</strong>, Quan Wang, Chen Qian, Feng Xu
              <br>
              <em>Transactions on Visualization and Computer Graphics (TVCG)</em>, 2022
              <p></p>
            </td>
        </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9756299/">
                <papertitle>[4] Structure-aware Editable Morphable Model for 3D Facial Detail Animation and Manipulation</papertitle>
              </a>
              <br>
              Jingwang Ling, Zhibo Wang, <strong>Ming Lu</strong>, Quan Wang, Chen Qian, Feng Xu
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022
              <p></p>
            </td>
        </tr>

	  <tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/abs/2309.12790">
                <papertitle>[5] NTO3D: Neural Target Object 3D Reconstruction with Segment Anything</papertitle>
              </a>
              <br>
              Xiaobao Wei, Renrui Zhang, Jiarui Wu, Jiaming Liu, <strong>Ming Lu</strong>, Yandong Guo, Shanghang Zhang
              <br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024
              <p></p>
            </td>
          </tr>

	  <tr>
            <td width="100%" valign="middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3664647.3681299">
                <papertitle>[6] Superpixel-based Efficient Sampling for Learning Neural Fields from Large Input</papertitle>
              </a>
              <br>
              Zhongwei Xuan, Zunjie Zhu, Shuai Wang, Haibing Yin, Hongkui Wang, <strong>Ming Lu</strong>
              <br>
              <em>International Conference on Multimedia (MM)</em>, 2024
              <p></p>
            </td>
          </tr>

	  <tr>
            <td width="100%" valign="middle">
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/32895/35050">
                <papertitle>[7] Graphavatar: Compact Head Avatars with GNN-Generated 3D Gaussians</papertitle>
              </a>
              <br>
              Xiaobao Wei, Peng Chen, <strong>Ming Lu</strong>, Hui Chen, Feng Tian
              <br>
              <em>Conference on Artificial Intelligence (AAAI)</em>, 2025
              <p></p>
            </td>
          </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2409.07200">
                <papertitle>[8] ThermalGaussian: Thermal 3D Gaussian Splatting</papertitle>
              </a>
              <br>
              Rongfeng Lu, Hangyu Chen, Zunjie Zhu, Yuhang Qin, <strong>Ming Lu</strong>, Le Zhang, Chenggang Yan, Anke Xue
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2025
              <p></p>
            </td>
          </tr>

	 <tr>
          <td width="100%" valign="middle">
            <a href="https://link.springer.com/content/pdf/10.1007/978-3-031-72684-2_6.pdf">
              <papertitle>[9] SliceOcc: Indoor 3D Semantic Occupancy Prediction with Vertical Slice Representation</papertitle>
            </a>
            <br>
            Jianing Li, <strong>Ming Lu</strong>, Hao Wang, Chenyang Gu, Wenzhao Zheng, Li Du, Shanghang Zhang
            <br>
            <em>International Conference on Robotics and Automation (ICRA)</em>, 2025
            <p></p>
          </td>
        </tr>

	<tr>
          <td width="100%" valign="middle">
            <a href="https://arxiv.org/pdf/2410.17505">
              <papertitle>[10] PLGS: Robust Panoptic Lifting with 3D Gaussian Splatting</papertitle>
            </a>
            <br>
            Yu Wang, Xiaobao Wei, <strong>Ming Lu</strong>, Guoliang Kang
            <br>
            <em>Transactions on Image Processing (TIP)</em>, 2025
            <p></p>
          </td>
        </tr>

	 <tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2505.19564">
                <papertitle>[11] K-Buffers: A Plug-in Method for Enhancing Neural Fields with Multiple Buffers</papertitle>
              </a>
              <br>
              Haofan Ren, Zunjie Zhu, Xiang Chen, <strong>Ming Lu</strong>, Rongfeng Lu, Chenggang Yan
              <br>
              <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2025
              <p></p>
            </td>
          </tr>

	  <tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2411.12981">
                <papertitle>[12] GazeGaussian: High-Fidelity Gaze Redirection with 3D Gaussian Splatting</papertitle>
              </a>
              <br>
              Xiaobao Wei, Peng Chen, Guangyu Li, <strong>Ming Lu</strong>, Hui Chen, Feng Tian
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2025
              <p></p>
            </td>
          </tr>

	  <tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2411.15582">
                <papertitle>[13] EMD: Explicit Motion Modeling for High-Quality Street Gaussian Splatting</papertitle>
              </a>
              <br>
              Xiaobao Wei, Qingpo Wuwu, Zhongyu Zhao, Zhuangzhe Wu, Nan Huang, <strong>Ming Lu</strong>, Ningning Ma, Shanghang Zhang
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2025
              <p></p>
            </td>
          </tr>
	
	<tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2406.04875">
                <papertitle>[14] 3DRealCar: An In-the-wild RGB-D Car Dataset with 360-degree Views</papertitle>
              </a>
              <br>
              Xiaobiao Du, Haiyang Sun, Shuyun Wang, Zhuojie Wu, Hongwei Sheng, Jiaying Ying, <strong>Ming Lu</strong>, Tianqing Zhu, Kun Zhan, Xin Yu
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2025
              <p></p>
            </td>
        </tr>
	      
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:0px;width:100%;vertical-align:middle">
          <heading><u>Small Computer Vision Models</u></heading>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Lu_Decoder_Network_Over_ICCV_2017_paper.pdf">
                <papertitle>[1] Decoder Network over Lightweight Reconstructed Feature for Fast Semantic Style Transfer</papertitle>
              </a>
              <br>
	      <strong>Ming Lu</strong>, Hao Zhao, Anbang Yao, Feng Xu, Yurong Chen, Li Zhang
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2017
              <p></p>
            </td>
        </tr>
	    
	<tr>
            <td width="100%" valign="middle">
              <a href="data/iccv2019_ost_paper.pdf">
                <papertitle>[2] A Closed-Form Solution to Universal Style Transfer</papertitle>
              </a>
              <br>
              <strong>Ming Lu</strong>, Hao Zhao, Anbang Yao, Yurong Chen, Feng Xu, Zhang Li
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2019
              <p></p>
            </td>
        </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3414685.3417824">
                <papertitle>[3] Single Image Portrait Relighting via Explicit Multiple Reflectance Channel Modeling</papertitle>
              </a>
              <br>
	      Zhibo Wang, Xin Yu, <strong>Ming Lu</strong>, Quan Wang, Chen Qian, Feng Xu
              <br>
              <em>ACM Transactions on Graphics (ToG)</em>, 2020
              <p></p>
            </td>
        </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Overfitting_the_Data_Compact_Neural_Video_Delivery_via_Content-Aware_Feature_ICCV_2021_paper.pdf">
                <papertitle>[4] Overfitting the Data: Compact Neural Video Delivery via Content-aware Feature Modulation</papertitle>
              </a>
              <br>
              Jiaming Liu, <strong>Ming Lu</strong>, Kaixin Chen, Xiaoqi Li, Shizun Wang, Zhaoqing Wang, Enhua Wu, Yurong Chen, Chuang Zhang, Ming Wu
              <br>
              <em>International Conference on Computer Vision (ICCV)</em>, 2021
              <p></p>
            </td>
        </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/1904.09105">
                <papertitle>[5] Deep Likelihood Network for Image Restoration With Multiple Degradation Levels</papertitle>
              </a>
              <br>
              Yiwen Guo, <strong>Ming Lu</strong>, Wangmeng Zuo, Changshui Zhang, Yurong Chen
              <br>
              <em>Transactions on Image Processing (TIP)</em>, 2021
              <p></p>
            </td>
          </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2111.15185">
                <papertitle>[6] SamplingAug: On the Importance of Patch Sampling Augmentation for Single Image Super-Resolution</papertitle>
              </a>
              <br>
              Shizun Wang, <strong>Ming Lu</strong>, Kaixin Chen, Jiaming Liu, Xiaoqi Li, Ming Wu
              <br>
              <em>British Machine Vision Conference (BMVC)</em>, 2021
              <p></p>
            </td>
          </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2207.09691">
                <papertitle>[7] Efficient Meta-Tuning for Content-Aware Neural Video Delivery</papertitle>
              </a>
              <br>
              Xiaoqi Li, Jiaming Liu, Shizun Wang, Cheng Lyu, <strong>Ming Lu</strong>, Yurong Chen, Anbang Yao, Yandong Guo, Shanghang Zhang
              <br>
              <em>European Conference on Computer Vision (ECCV)</em>, 2022
              <p></p>
            </td>
          </tr>

	<tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2203.11589">
                <papertitle>[8] Adaptive Patch Exiting for Scalable Single Image Super-Resolution</papertitle>
              </a>
              <br>
              Shizun Wang, Jiaming Liu, Kaixin Chen, Xiaoqi Li, <strong>Ming Lu</strong>, Yandong Guo
              <br>
              <em>European Conference on Computer Vision (ECCV Oral)</em>, 2022
              <p></p>
            </td>
          </tr>
	    
	<tr>
            <td width="100%" valign="middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_CABM_Content-Aware_Bit_Mapping_for_Single_Image_Super-Resolution_Network_With_CVPR_2023_paper.pdf">
                <papertitle>[9] CABM: Content-Aware Bit Mapping for Single Image Super-Resolution Network with Large Input</papertitle>
              </a>
              <br>
              Senmao Tian, <strong>Ming Lu</strong>, Jiaming Liu, Yandong Guo, Yurong Chen, Shunli Zhang
              <br>
              <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023
              <p></p>
            </td>
          </tr>

	   <tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/pdf/2304.06497">
                <papertitle>[10] A Comprehensive Comparison of Projections in Omnidirectional Super-Resolution</papertitle>
              </a>
              <br>
	      Huicheng Pi, Senmao Tian, <strong>Ming Lu</strong>, Jiaming Liu, Yandong Guo, Shunli Zhang
              <br>
	      <em>International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2023
              <p></p>
            </td>
          </tr>

	   <tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/10219822/">
                <papertitle>[11] DanceU: Motion-and-Music-based Automatic Effect Generation for Dance Videos</papertitle>
              </a>
              <br>
	      Yanjie Pan, Yaru Du, Shandong Wang, Yun Ye, Yong Jiang, Zhen Zhou, Li Xu, <strong>Ming Lu</strong>, Yunbiao Lin, Jiehui Lu
              <br>
	      <em>International Conference on Multimedia and Expo (ICME)</em>, 2023
              <p></p>
            </td>
          </tr>

	   <tr>
            <td width="100%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/10222306">
                <papertitle>[12] HQRetouch: Learning Professional Face Retouching via Masked Feature Fusion and Semantic-aware Modulation</papertitle>
              </a>
              <br>
	      Gangyi Hong, Fangshi Wang, Senmao Tian, <strong>Ming Lu</strong>, Jiaming Liu, Shunli Zhang
              <br>
	      <em>International Conference on Multimedia and Expo (ICME)</em>, 2023
              <p></p>
            </td>
          </tr>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:0px;width:100%;vertical-align:middle">
          <heading><u>AI for Sciences</u></heading>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>
          <td width="100%" valign="middle">
            <a href="https://link.springer.com/content/pdf/10.1007/978-3-031-72684-2_6.pdf">
              <papertitle>[1] I-MedSAM: Implicit Medical Image Segmentation with Segment Anything</papertitle>
            </a>
            <br>
            Xiaobao Wei, Jiajun Cao, Yizhu Jin, <strong>Ming Lu</strong>, Guangyu Wang, Shanghang Zhang
            <br>
            <em>European Conference on Computer Vision (ECCV)</em>, 2024
            <p></p>
          </td>
        </tr>
	    
	<tr>
          <td width="100%" valign="middle">
            <a href="">
              <papertitle>[2] A Generalist Foundation Model and Database for Open-World Medical Image Segmentation</papertitle>
            </a>
            <br>
            Siqi Zhang, Qizhe Zhang, Shanghang Zhang, Xiaohong Liu, Jingkun Yue, <strong>Ming Lu</strong>, ..., Guangyu Wang
            <br>
            <em>Nature Biomedical Engineering (NBE)</em>, 2025
            <p></p>
          </td>
        </tr>

    	<tr>
            <td width="100%" valign="middle">
              <a href="https://arxiv.org/abs/2405.19012">
                <papertitle>[3] Implicit Neural Image Field for Biological Microscopy Image Compression</papertitle>
              </a>
              <br>
              Gaole Dai, Cheng-Ching Tseng, Qingpo Wuwu, Rongyu Zhang, Shaokang Wang, <strong>Ming Lu</strong>,..., Jianxu Chen, Shanghang Zhang
              <br>
              <em>Nature Computational Science (NCS)</em>, 2025
              <p></p>
            </td>
        </tr>

    </tbody></table>	
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr>
            <td>
              <heading><u>Application Demos</u></heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="0"><tbody>

        <tr>
          <td style="padding:0px;width:25%;vertical-align:middle"><img src="images/proj2017_chris.jpg" alt="blind-date" width="160" height="100"></td>
          <td width="75%" valign="center">
            <a href="https://www.youtube.com/watch?v=c5-iIheUlyI">Our 3D face technique has been applied to Chris Lee's MV</a>
          </td>
        </tr>

        <tr>
          <td style="padding:0px;width:25%;vertical-align:middle"><img src="images/proj2022_olympic.jpg" alt="blind-date" width="160" height="120"></td>
          <td width="75%" valign="center">
            <a href="https://www.intel.com/content/www/us/en/sports/olympic-games/overview.html">Our 3D body technique has been applied to the opening ceremony of Winter Olympic Games 2022</a>
          </td>
        </tr>
				
      </td>
    </tr>
  </table>
</body>

</html>
